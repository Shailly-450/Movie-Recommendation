{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "WEeZZmV7ZW5y",
        "outputId": "41e5a427-63f7-4655-af13-0fe1029ce784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.14.1)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m177.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.40.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "85dd37d7998842e8af8707dae68bb28f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.23.5 scikit-surprise --no-cache-dir\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "B3HzKDQtt-OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nltk\n",
        "import re\n",
        "import warnings\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml9Y8yINnTcR",
        "outputId": "6ec2e8db-60a3-46c0-9629-0244c27b3557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get dataset path"
      ],
      "metadata": {
        "id": "Nc1Zd2F0uF2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"grouplens/movielens-20m-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gc7_WNPpd4w",
        "outputId": "8705d74c-42dd-4948-d3ce-4198c7d5ae60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/grouplens/movielens-20m-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195M/195M [00:01<00:00, 165MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/grouplens/movielens-20m-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "J77oiewSuONg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MovieLens dataset\n",
        "movies = pd.read_csv(\"/content/movie.csv\")\n",
        "ratings = pd.read_csv(\"/content/rating.csv\")"
      ],
      "metadata": {
        "id": "fGJDhWljZt2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge Dataset"
      ],
      "metadata": {
        "id": "Yp3W5_qSuVdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets\n",
        "data = ratings.merge(movies, on=\"movieId\")"
      ],
      "metadata": {
        "id": "9AryaOBuZ6JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering"
      ],
      "metadata": {
        "id": "PrS7gLwjuuRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collaborative Filtering (Matrix Factorization using SVD)\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "dataset = Dataset.load_from_df(data[['userId', 'movieId', 'rating']], reader)\n",
        "trainset, testset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "model_cf = SVD()\n",
        "model_cf.fit(trainset)"
      ],
      "metadata": {
        "id": "iCR3vdEGZ6Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75239378-7b47-4fa3-c29e-dd92e8c0dbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7e1bf0e0dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Content-Based Filtering"
      ],
      "metadata": {
        "id": "-RyW9mFrvhlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Content-Based Filtering using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "movie_tfidf = vectorizer.fit_transform(movies['title'])\n",
        "cosine_sim = cosine_similarity(movie_tfidf, movie_tfidf)"
      ],
      "metadata": {
        "id": "_YR0A1aTZ6SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "nS10NF5ivm_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis\n",
        "sanalyzer = SentimentIntensityAnalyzer()\n",
        "def analyze_sentiment(review):\n",
        "    return sanalyzer.polarity_scores(review)['compound']"
      ],
      "metadata": {
        "id": "fgh4VFrfbDMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation Function"
      ],
      "metadata": {
        "id": "HzHdL9BUvqTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendation Function\n",
        "def hybrid_recommend(user_id, num_recommendations=5):\n",
        "    user_movies = data[data['userId'] == user_id]['movieId'].tolist()\n",
        "\n",
        "    pred_ratings = [(mid, model_cf.predict(user_id, mid).est) for mid in movies['movieId'] if mid not in user_movies]\n",
        "    pred_ratings = sorted(pred_ratings, key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
        "\n",
        "    recommended_movies = []\n",
        "    for movie_id, rating in pred_ratings:\n",
        "        similar_movies = list(enumerate(cosine_sim[movies[movies['movieId'] == movie_id].index[0]]))\n",
        "        similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "        movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "        recommended_movies.append((movie_title, rating))\n",
        "\n",
        "    return recommended_movies"
      ],
      "metadata": {
        "id": "eTVPwSpqbDbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save models for Flask"
      ],
      "metadata": {
        "id": "AzEAj5OVvtwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models for Flask\n",
        "with open(\"hybrid_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_cf, f)\n",
        "\n",
        "with open(\"cosine_sim.pkl\", \"wb\") as f:\n",
        "    pickle.dump(cosine_sim, f)\n",
        "\n",
        "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorizer, f)"
      ],
      "metadata": {
        "id": "c_1J6XkHbDfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Recommendation System"
      ],
      "metadata": {
        "id": "qIwMDitjvx23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n",
        "\n",
        "# Test Recommendation System\n",
        "from tabulate import tabulate\n",
        "\n",
        "table = hybrid_recommend(user_id=1)\n",
        "print(tabulate(table, headers=[\"Movie\", \"Predicted Rating\"]))"
      ],
      "metadata": {
        "id": "6nOcMxc2bDhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abd2f4c-b388-43be-d3a1-bdcabfd351cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Movie                                      Predicted Rating\n",
            "---------------------------------------  ------------------\n",
            "Cosmos (1980)                                       4.50483\n",
            "Black Mirror (2011)                                 4.48393\n",
            "Thin Blue Line, The (1988)                          4.474\n",
            "Baraka (1992)                                       4.4558\n",
            "My Life in Pink (Ma vie en rose) (1997)             4.44077\n"
          ]
        }
      ]
    }
  ]
}